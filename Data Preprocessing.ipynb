{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://github.com/imdeepmind/TextPreprocessingScript/blob/master/preprocess.py\n",
    "class Preprocess:\n",
    "    def sentence_tokenizer(self, doc):\n",
    "        return sent_tokenize(doc)\n",
    "    \n",
    "    def word_tokenizer(self, sentence):\n",
    "        return word_tokenize(sentence) \n",
    "    \n",
    "    def remove_stop_words(self, tokenized_sentences):\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        return [t for t in tokenized_sentences if not t in stop_words] \n",
    "    \n",
    "    def normalize(self, doc):\n",
    "        doc = doc.lower()\n",
    "        \n",
    "        doc = re.sub(r\"i'm\", \"i am\", doc)\n",
    "        doc = re.sub(r\"aren't\", \"are not\", doc)\n",
    "        doc = re.sub(r\"couldn't\", \"counld not\", doc)\n",
    "        doc = re.sub(r\"didn't\", \"did not\", doc)\n",
    "        doc = re.sub(r\"doesn't\", \"does not\", doc)\n",
    "        doc = re.sub(r\"don't\", \"do not\", doc)\n",
    "        doc = re.sub(r\"hadn't\", \"had not\", doc)\n",
    "        doc = re.sub(r\"hasn't\", \"has not\", doc)\n",
    "        doc = re.sub(r\"haven't\", \"have not\", doc)\n",
    "        doc = re.sub(r\"isn't\", \"is not\", doc)\n",
    "        doc = re.sub(r\"it't\", \"had not\", doc)\n",
    "        doc = re.sub(r\"hadn't\", \"had not\", doc)\n",
    "        doc = re.sub(r\"won't\", \"will not\", doc)\n",
    "        doc = re.sub(r\"can't\", \"cannot\", doc)\n",
    "        doc = re.sub(r\"mightn't\", \"might not\", doc)\n",
    "        doc = re.sub(r\"mustn't\", \"must not\", doc)\n",
    "        doc = re.sub(r\"needn't\", \"need not\", doc)\n",
    "        doc = re.sub(r\"shouldn't\", \"should not\", doc)\n",
    "        doc = re.sub(r\"wasn't\", \"was not\", doc)\n",
    "        doc = re.sub(r\"weren't\", \"were not\", doc)\n",
    "        doc = re.sub(r\"won't\", \"will not\", doc)\n",
    "        doc = re.sub(r\"wouldn't\", \"would not\", doc)\n",
    "        \n",
    "        doc = re.sub(r\"\\'s\", \" is\", doc)\n",
    "        doc = re.sub(r\"\\'ll\", \" will\", doc)\n",
    "        doc = re.sub(r\"\\'ve\", \" have\", doc)\n",
    "        doc = re.sub(r\"\\'re\", \" are\", doc)\n",
    "        doc = re.sub(r\"\\'d\", \" would\", doc)\n",
    "        \n",
    "        return doc\n",
    "    \n",
    "    def remove_unchars(self, doc):\n",
    "        doc = re.sub(r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))''', '', doc, flags=re.MULTILINE)\n",
    "        doc = re.sub(r'(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)', '', doc)\n",
    "        doc = re.sub(r'\\b[0-9]+\\b\\s*', '', doc)\n",
    "        \n",
    "        return doc\n",
    "    \n",
    "    \n",
    "    def get_pos(self, sentence):\n",
    "        \"\"\"\n",
    "            This method is used for POS tagging\n",
    "        \"\"\"\n",
    "        pos = []\n",
    "        for word in sentence:\n",
    "            w, p = nltk.pos_tag([word])[0]\n",
    "            if p.startswith('J'):\n",
    "                pos.append((w, wordnet.ADJ))\n",
    "            elif p.startswith('V'):\n",
    "                pos.append((w, wordnet.VERB))\n",
    "            elif p.startswith('N'):\n",
    "                pos.append((w, wordnet.NOUN))\n",
    "            elif p.startswith('R'):\n",
    "                pos.append((w, wordnet.ADV))\n",
    "            else:\n",
    "                pos.append(('',''))\n",
    "    \n",
    "        return pos\n",
    "    \n",
    "    def lemmatizer(self, words):\n",
    "        lemmatizer = WordNetLemmatizer() \n",
    "        lemmatized_sentence = []\n",
    "    \n",
    "        for word in words:\n",
    "            w,p = self.get_pos([word])[0]\n",
    "            if p != '':\n",
    "                w = lemmatizer.lemmatize(word, pos=p)\n",
    "            else:\n",
    "                w = lemmatizer.lemmatize(word)\n",
    "            lemmatized_sentence.append(w)\n",
    "        \n",
    "        return lemmatized_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/processed_data1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>subject</th>\n",
       "      <th>email_to</th>\n",
       "      <th>email_from</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Generic Cialis, branded quality@</td>\n",
       "      <td>the00@speedy.uwaterloo.ca</td>\n",
       "      <td>\"Tomas Jacobs\" &lt;RickyAmes@aol.com&gt;</td>\n",
       "      <td>Content-Type: text/html;\\nContent-Transfer-Enc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Typo in /debian/README</td>\n",
       "      <td>debian-mirrors@lists.debian.org</td>\n",
       "      <td>Yan Morin &lt;yan.morin@savoirfairelinux.com&gt;</td>\n",
       "      <td>Hi, i've just updated from the gulus and I che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>authentic viagra</td>\n",
       "      <td>&lt;the00@plg.uwaterloo.ca&gt;</td>\n",
       "      <td>\"Sheila Crenshaw\" &lt;7stocknews@tractionmarketin...</td>\n",
       "      <td>Content-Type: text/plain;\\n\\tcharset=\"iso-8859...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Nice talking with ya</td>\n",
       "      <td>opt4@speedy.uwaterloo.ca</td>\n",
       "      <td>\"Stormy Dempsey\" &lt;vqucsmdfgvsg@ruraltek.com&gt;</td>\n",
       "      <td>\\nHey Billy, \\n\\nit was really fun going out t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>or trembling; stomach cramps; trouble in sleep...</td>\n",
       "      <td>ktwarwic@speedy.uwaterloo.ca</td>\n",
       "      <td>\"Christi T. Jernigan\" &lt;dcube@totalink.net&gt;</td>\n",
       "      <td>Content-Type: multipart/alternative;\\n        ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            subject  \\\n",
       "0      1                  Generic Cialis, branded quality@    \n",
       "1      0                             Typo in /debian/README   \n",
       "2      1                                   authentic viagra   \n",
       "3      1                               Nice talking with ya   \n",
       "4      1  or trembling; stomach cramps; trouble in sleep...   \n",
       "\n",
       "                          email_to  \\\n",
       "0        the00@speedy.uwaterloo.ca   \n",
       "1  debian-mirrors@lists.debian.org   \n",
       "2         <the00@plg.uwaterloo.ca>   \n",
       "3         opt4@speedy.uwaterloo.ca   \n",
       "4     ktwarwic@speedy.uwaterloo.ca   \n",
       "\n",
       "                                          email_from  \\\n",
       "0                 \"Tomas Jacobs\" <RickyAmes@aol.com>   \n",
       "1         Yan Morin <yan.morin@savoirfairelinux.com>   \n",
       "2  \"Sheila Crenshaw\" <7stocknews@tractionmarketin...   \n",
       "3       \"Stormy Dempsey\" <vqucsmdfgvsg@ruraltek.com>   \n",
       "4         \"Christi T. Jernigan\" <dcube@totalink.net>   \n",
       "\n",
       "                                             message  \n",
       "0  Content-Type: text/html;\\nContent-Transfer-Enc...  \n",
       "1  Hi, i've just updated from the gulus and I che...  \n",
       "2  Content-Type: text/plain;\\n\\tcharset=\"iso-8859...  \n",
       "3  \\nHey Billy, \\n\\nit was really fun going out t...  \n",
       "4  Content-Type: multipart/alternative;\\n        ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = Preprocess()\n",
    "\n",
    "def remove_html(message):\n",
    "    soup = BeautifulSoup(message)\n",
    "    for s in soup(['script', 'style', 'head', 'meta', 'noscript']):\n",
    "        s.decompose()\n",
    "    return ' '.join(soup.stripped_strings)\n",
    "\n",
    "def clean_subject(subject):\n",
    "    if isinstance(subject, str):\n",
    "        subject = preprocess.normalize(subject)\n",
    "        subject = preprocess.remove_unchars(subject)\n",
    "        \n",
    "        return subject\n",
    "    \n",
    "    return None\n",
    "\n",
    "def get_emails(text):\n",
    "    if isinstance(text, str):\n",
    "        match = re.search(r'[\\w\\.-]+@[\\w\\.-]+', text)\n",
    "    \n",
    "        return match.group(0) if match else None\n",
    "    \n",
    "    return None\n",
    "\n",
    "def clean_messages(message):\n",
    "    if isinstance(message, str):\n",
    "        message = remove_html(message)\n",
    "\n",
    "        message = preprocess.normalize(message)\n",
    "        message = preprocess.remove_unchars(message)\n",
    "\n",
    "        return message\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 48677/75419 [04:16<02:04, 214.35it/s]/usr/lib/python3.9/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"http://yenibiris.sendeyolla.com/medyadetay.aspx?&tid=3&cid=57&id=61365\n",
      "\n",
      "\n",
      "\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n",
      "100%|██████████| 75419/75419 [06:29<00:00, 193.79it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "def process_df(df):\n",
    "    df[\"subject\"] = clean_subject(df[\"subject\"])\n",
    "    df[\"email_to\"] = get_emails(df[\"email_to\"])\n",
    "    df[\"email_from\"] = get_emails(df[\"email_from\"])\n",
    "    df[\"message\"] = clean_messages(df[\"message\"])\n",
    "    \n",
    "    return df\n",
    "\n",
    "data = data.progress_apply(process_df, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>subject</th>\n",
       "      <th>email_to</th>\n",
       "      <th>email_from</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>generic cialis branded quality</td>\n",
       "      <td>the00@speedy.uwaterloo.ca</td>\n",
       "      <td>RickyAmes@aol.com</td>\n",
       "      <td>contenttype texthtmlcontenttransferencoding 7b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>typo in debianreadme</td>\n",
       "      <td>debian-mirrors@lists.debian.org</td>\n",
       "      <td>yan.morin@savoirfairelinux.com</td>\n",
       "      <td>hi i have just updated from the gulus and i ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>authentic viagra</td>\n",
       "      <td>the00@plg.uwaterloo.ca</td>\n",
       "      <td>7stocknews@tractionmarketing.com</td>\n",
       "      <td>contenttype textplain\\tcharsetiso88591contentt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>nice talking with ya</td>\n",
       "      <td>opt4@speedy.uwaterloo.ca</td>\n",
       "      <td>vqucsmdfgvsg@ruraltek.com</td>\n",
       "      <td>hey billy it was really fun going out the othe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>or trembling stomach cramps trouble in sleepin...</td>\n",
       "      <td>ktwarwic@speedy.uwaterloo.ca</td>\n",
       "      <td>dcube@totalink.net</td>\n",
       "      <td>contenttype multipartalternative        bounda...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            subject  \\\n",
       "0      1                    generic cialis branded quality    \n",
       "1      0                               typo in debianreadme   \n",
       "2      1                                   authentic viagra   \n",
       "3      1                               nice talking with ya   \n",
       "4      1  or trembling stomach cramps trouble in sleepin...   \n",
       "\n",
       "                          email_to                        email_from  \\\n",
       "0        the00@speedy.uwaterloo.ca                 RickyAmes@aol.com   \n",
       "1  debian-mirrors@lists.debian.org    yan.morin@savoirfairelinux.com   \n",
       "2           the00@plg.uwaterloo.ca  7stocknews@tractionmarketing.com   \n",
       "3         opt4@speedy.uwaterloo.ca         vqucsmdfgvsg@ruraltek.com   \n",
       "4     ktwarwic@speedy.uwaterloo.ca                dcube@totalink.net   \n",
       "\n",
       "                                             message  \n",
       "0  contenttype texthtmlcontenttransferencoding 7b...  \n",
       "1  hi i have just updated from the gulus and i ch...  \n",
       "2  contenttype textplain\\tcharsetiso88591contentt...  \n",
       "3  hey billy it was really fun going out the othe...  \n",
       "4  contenttype multipartalternative        bounda...  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75419, 5)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73897, 5)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"data/processed_data2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
